(dp0
VBody
p1
V<p>I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code.  Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something.  </p>\u000a\u000a<hr>\u000a\u000a<p>(tl;dr version: include the statement: cin.sync_with_stdio(false) or just use fgets instead.</p>\u000a\u000a<p>tl;dr results: scroll all the way down to the bottom of my question and look at the table.)</p>\u000a\u000a<hr>\u000a\u000a<p><strong>C++ code:</strong></p>\u000a\u000a<pre><code>#include &lt;iostream&gt;\u000a#include &lt;time.h&gt;\u000a\u000ausing namespace std;\u000a\u000aint main() {\u000a    string input_line;\u000a    long line_count = 0;\u000a    time_t start = time(NULL);\u000a    int sec;\u000a    int lps;                                                                   \u000a\u000a    while (cin) {\u000a        getline(cin, input_line);\u000a        if (!cin.eof())\u000a            line_count++;\u000a    };\u000a\u000a    sec = (int) time(NULL) - start;\u000a    cerr &lt;&lt; "Saw " &lt;&lt; line_count &lt;&lt; " lines in " &lt;&lt; sec &lt;&lt; " seconds." ;\u000a    if (sec &gt; 0) {\u000a        lps = line_count / sec;\u000a        cerr &lt;&lt; "  Crunch speed: " &lt;&lt; lps &lt;&lt; endl;\u000a    } else\u000a        cerr &lt;&lt; endl;\u000a    return 0;\u000a}\u000a\u000a//Compiled with:\u000a//g++ -O3 -o readline_test_cpp foo.cpp\u000a</code></pre>\u000a\u000a<p><strong>Python Equivalent:</strong></p>\u000a\u000a<pre><code>#!/usr/bin/env python\u000aimport time\u000aimport sys\u000a\u000acount = 0\u000astart = time.time()\u000a\u000afor line in  sys.stdin:\u000a    count += 1\u000a\u000adelta_sec = int(time.time() - start_time)\u000aif delta_sec &gt;= 0:\u000a    lines_per_sec = int(round(count/delta_sec))\u000a    print("Read {0:n} lines in {1:n} seconds. LPS: {2:n}".format(count, delta_sec,\u000a       lines_per_sec))\u000a</code></pre>\u000a\u000a<p><strong>Here are my results:</strong></p>\u000a\u000a<pre><code>$ cat test_lines | ./readline_test_cpp \u000aSaw 5570000 lines in 9 seconds.  Crunch speed: 618889\u000a\u000a$cat test_lines | ./readline_test.py \u000aRead 5570000 lines in 1 seconds. LPS: 5570000\u000a</code></pre>\u000a\u000a<p>Thanks in advance!</p>\u000a\u000a<p><strong>Edit:</strong> <em>I should note that I tried this both under OS-X (10.6.8) and Linux 2.6.32 (RHEL 6.2).  The former is a macbook pro, the latter is a very beefy server, not that this is too pertinent.</em></p>\u000a\u000a<p><strong>Edit 2:</strong> <em>(Removed this edit, as no longer applicable)</em></p>\u000a\u000a<pre><code>$ for i in {1..5}; do echo "Test run $i at `date`"; echo -n "CPP:"; cat test_lines | ./readline_test_cpp ; echo -n "Python:"; cat test_lines | ./readline_test.py ; done\u000aTest run 1 at Mon Feb 20 21:29:28 EST 2012\u000aCPP:Saw 5570001 lines in 9 seconds.  Crunch speed: 618889\u000aPython:Read 5,570,000 lines in 1 seconds. LPS: 5,570,000\u000aTest run 2 at Mon Feb 20 21:29:39 EST 2012\u000aCPP:Saw 5570001 lines in 9 seconds.  Crunch speed: 618889\u000aPython:Read 5,570,000 lines in 1 seconds. LPS: 5,570,000\u000aTest run 3 at Mon Feb 20 21:29:50 EST 2012\u000aCPP:Saw 5570001 lines in 9 seconds.  Crunch speed: 618889\u000aPython:Read 5,570,000 lines in 1 seconds. LPS: 5,570,000\u000aTest run 4 at Mon Feb 20 21:30:01 EST 2012\u000aCPP:Saw 5570001 lines in 9 seconds.  Crunch speed: 618889\u000aPython:Read 5,570,000 lines in 1 seconds. LPS: 5,570,000\u000aTest run 5 at Mon Feb 20 21:30:11 EST 2012\u000aCPP:Saw 5570001 lines in 10 seconds.  Crunch speed: 557000\u000aPython:Read 5,570,000 lines in 1 seconds. LPS: 5,570,000\u000a</code></pre>\u000a\u000a<p><strong>Edit 3:</strong> </p>\u000a\u000a<p>Okay, I tried J.N.'s suggestion of trying having python store the line read: but it made no difference to python's speed.  </p>\u000a\u000a<p>I also tried J.N.'s suggestion of using scanf into a char array instead of getline into a std::string.  Bingo!  This resulted in equivalent performance for both python and c++. (3,333,333 LPS with my input data, which by the way are just short lines of three fields each, usually about 20 chars wide, though sometimes more).</p>\u000a\u000a<p>Code:</p>\u000a\u000a<pre><code>char input_a[512];\u000achar input_b[32];\u000achar input_c[512];\u000awhile(scanf("%s %s %s\u005cn", input_a, input_b, input_c) != EOF) {             \u000a    line_count++;\u000a};\u000a</code></pre>\u000a\u000a<p>Speed:</p>\u000a\u000a<pre><code>$ cat test_lines | ./readline_test_cpp2 \u000aSaw 10000000 lines in 3 seconds.  Crunch speed: 3333333\u000a$ cat test_lines | ./readline_test2.py \u000aRead 10000000 lines in 3 seconds. LPS: 3333333\u000a</code></pre>\u000a\u000a<p>(Yes, I ran it several times.) So, I guess I will now use scanf instead of getline.  But, I'm still curious if people think this performance hit from std::string/getline is typical and reasonable. </p>\u000a\u000a<p><strong>Edit 4 (was: Final Edit / Solution):</strong></p>\u000a\u000a<p>Adding:\u000a    cin.sync_with_stdio(false);</p>\u000a\u000a<p>Immediately above my original while loop above results in code that runs faster than Python.  </p>\u000a\u000a<p><strong>New performance comparison</strong> (this is on my 2011 Macbook Pro), using the original code, the original with the sync disabled, and the original python, respectively, on a file with 20M lines of text.  Yes, I ran it several times to eliminate disk caching confound.</p>\u000a\u000a<pre><code>$ /usr/bin/time cat test_lines_double | ./readline_test_cpp\u000a       33.30 real         0.04 user         0.74 sys\u000aSaw 20000001 lines in 33 seconds.  Crunch speed: 606060\u000a$ /usr/bin/time cat test_lines_double | ./readline_test_cpp1b\u000a        3.79 real         0.01 user         0.50 sys\u000aSaw 20000000 lines in 4 seconds.  Crunch speed: 5000000\u000a$ /usr/bin/time cat test_lines_double | ./readline_test.py \u000a        6.88 real         0.01 user         0.38 sys\u000aRead 20000000 lines in 6 seconds. LPS: 3333333\u000a</code></pre>\u000a\u000a<p>Thanks to @Vaughn Cato for his answer!  <strong><em>Any elaboration people can make or good references people can point to as to why this sync happens, what it means, when it's useful, and when it's okay to disable would be greatly appreciated by posterity.</em></strong> :-)</p>\u000a\u000a<p><strong>Edit 5 / Better Solution:</strong></p>\u000a\u000a<p>As suggested by Gandalf The Gray below, gets is even faster than scanf or the unsynchronized cin approach.  I also learned that <a href="http://c-faq.com/stdio/scanfprobs.html">scanf</a> and <a href="http://c-faq.com/stdio/getsvsfgets.html">gets</a> are both UNSAFE and should NOT BE USED due to potential of buffer overflow.  So, I wrote this iteration using fgets, the safer alternative to gets.  Here are the pertinent lines for my fellow noobs:</p>\u000a\u000a<pre><code>char input_line[MAX_LINE];\u000achar *result;\u000a\u000a//&lt;snip&gt;\u000a\u000awhile((result = fgets(input_line, MAX_LINE, stdin )) != NULL)    \u000a    line_count++;\u000aif (ferror(stdin))\u000a    perror("Error reading stdin.");\u000a</code></pre>\u000a\u000a<p>Now, here are the results using an even larger file (100M lines; ~3.4GB) on a fast server with very fast disk, comparing the python, the unsynced cin, and the fgets approaches, as well as comparing with the wc utility.  [The scanf version segfaulted and I don't feel like troubleshooting it.]:</p>\u000a\u000a<pre><code>$ /usr/bin/time cat temp_big_file | readline_test.py \u000a0.03user 2.04system 0:28.06elapsed 7%CPU (0avgtext+0avgdata 2464maxresident)k\u000a0inputs+0outputs (0major+182minor)pagefaults 0swaps\u000aRead 100000000 lines in 28 seconds. LPS: 3571428\u000a\u000a$ /usr/bin/time cat temp_big_file | readline_test_unsync_cin \u000a0.03user 1.64system 0:08.10elapsed 20%CPU (0avgtext+0avgdata 2464maxresident)k\u000a0inputs+0outputs (0major+182minor)pagefaults 0swaps\u000aSaw 100000000 lines in 8 seconds.  Crunch speed: 12500000\u000a\u000a$ /usr/bin/time cat temp_big_file | readline_test_fgets \u000a0.00user 0.93system 0:07.01elapsed 13%CPU (0avgtext+0avgdata 2448maxresident)k\u000a0inputs+0outputs (0major+181minor)pagefaults 0swaps\u000aSaw 100000000 lines in 7 seconds.  Crunch speed: 14285714\u000a\u000a$ /usr/bin/time cat temp_big_file | wc -l\u000a0.01user 1.34system 0:01.83elapsed 74%CPU (0avgtext+0avgdata 2464maxresident)k\u000a0inputs+0outputs (0major+182minor)pagefaults 0swaps\u000a100000000\u000a\u000aRecap (lines per second):\u000apython:         3,571,428 \u000acin (no sync): 12,500,000\u000afgets:         14,285,714\u000awc:            54,644,808\u000a</code></pre>\u000a\u000a<p>As you can see, fgets is better but still pretty far from wc performance; I'm pretty sure this is due to the fact that wc examines each character without any memory copying.  I suspect that, at this point, other parts of the code will become the bottleneck, so I don't think optimizing to that level would even be worthwhile, even if possible (since, after all, I actually need to store the read lines in memory).  </p>\u000a\u000a<p>Also note that a small tradeoff with using a char * buffer and fgets vs unsynced cin to string is that the latter can read lines of any length, while the former requires limiting input to some finite number.  In practice, this is probably a non-issue for reading most line-based input files, as the buffer can be set to a very large value that would not be exceeded by valid input. </p>\u000a\u000a<p>This has been educational.  Thanks to all for your comments and suggestions.</p>\u000a\u000a<p><strong>Edit 6:</strong></p>\u000a\u000a<p>As suggested by J.F. Sebastian in the comments below, the GNU wc utility uses plain C read() (within the safe-read.c wrapper) to read chunks (of 16k bytes) at a time and count new lines.  Here's a python equivalent based on J.F.'s code (just showing the relevant snippet that replaces the python for loop:</p>\u000a\u000a<pre><code>BUFFER_SIZE = 16384 \u000acount = sum(chunk.count('\u005cn') for chunk in iter(partial(sys.stdin.read, BUFFER_SIZE), ''))\u000a</code></pre>\u000a\u000a<p>The performance of this version is quite fast (though still a bit slower than the raw c wc utility, of course:</p>\u000a\u000a<pre><code>$ /usr/bin/time cat temp_big_file | readline_test3.py \u000a0.01user 1.16system 0:04.74elapsed 24%CPU (0avgtext+0avgdata 2448maxresident)k\u000a0inputs+0outputs (0major+181minor)pagefaults 0swaps\u000aRead 100000000 lines in 4.7275 seconds. LPS: 21152829\u000a</code></pre>\u000a\u000a<p>Again, it's a bit silly for me to compare C++ fgets/cin and the first python code on the one hand to wc -l and this last python snippet on the other, as the latter two don't actually store the read lines but merely count newlines.  Still, it's interesting to explore all the different implementations and think about the performance implications.  Thanks again!</p>\u000a\u000a<p><strong>Edit 7: Tiny benchmark addendum and recap</strong></p>\u000a\u000a<p>(Hello HN readers!)   </p>\u000a\u000a<p>For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code.  Again, this is for a 100M line file on a fast disk. Here's the complete table now:</p>\u000a\u000a<pre><code>Implementation      Lines per second\u000apython (default)           3,571,428\u000acin (default/naive)          819,672\u000acin (no sync)             12,500,000\u000afgets                     14,285,714\u000awc (not fair comparison)  54,644,808\u000a</code></pre>\u000a\u000a<p>Also, see my follow-up <a href="http://stackoverflow.com/questions/9378500/why-is-splitting-a-string-slower-in-c-than-python">question</a> about splitting lines in C++ vs Python... a similar speed story, where the naive approach is slower in C++!</p>\u000a\u000a<p>Edit: for clarity, removed tiny bug in original code that wasn't related to the question.</p>\u000a
p2
sVViewCount
p3
I80131
sVCreationDate
p4
cdatetime
datetime
p5
(S'\x07\xdc\x02\x15\x02\x112\x07\x10\x98'
p6
tp7
Rp8
sVTags
p9
(lp10
Vc++
p11
aVpython
p12
aVbenchmarking
p13
aVreadline
p14
aVgetline
p15
asVLastEditorUserId
p16
I379037
sVLastActivityDate
p17
g5
(S'\x07\xde\x04\x17\x0e8\x18\x07S\x00'
p18
tp19
Rp20
sVLastEditDate
p21
g5
(S'\x07\xde\x01\x0f\x10,8\x0e~\xf0'
p22
tp23
Rp24
sVCommentCount
p25
I26
sVAnswerCount
p26
I12
sVOwnerUserId
p27
I379037
sVAcceptedAnswerId
p28
I9371717
sVScore
p29
I497
sVTitle
p30
VWhy is reading lines from stdin much slower in C++ than Python?
p31
sVPostTypeId
p32
I1
sVCommunityOwnedDate
p33
g5
(S'\x07\xdc\x06\r\x13\x03\x13\x07\x04\xe0'
p34
tp35
Rp36
sV_id
p37
ccopy_reg
_reconstructor
p38
(cbson.objectid
ObjectId
p39
c__builtin__
object
p40
Ntp41
Rp42
S"S\x82n4B\x1a\xa9d\xb6\x9al'"
p43
bsVFavoriteCount
p44
I318
sVId
p45
I9371238
s.